import json
import argparse
import os
import random
import asyncio
import aiohttp
import re
import uuid
import sys
from typing import List, Dict, Any, Optional
from tqdm.asyncio import tqdm

# ==========================================
# åŸºç¡€å·¥å…·æ¨¡å—
# ==========================================

def load_original_data(input_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½åŸå§‹æ•°æ® (JSONL)"""
    data = []
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and line.startswith('{'):
                    try:
                        data.append(json.loads(line))
                    except:
                        pass
        return data
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {input_path}")
        return []

def save_lines_append(file_path: str, data_list: List[Dict[str, Any]]):
    """é€šç”¨è¿½åŠ å†™å…¥å·¥å…·"""
    if not data_list:
        return
    with open(file_path, 'a+', encoding='utf-8') as f:
        for item in data_list:
            json.dump(item, f, ensure_ascii=False)
            f.write('\n')

def extract_questions_1hop(q_chain: List[Dict[str, Any]]) -> Dict[str, str]:
    """
    [L1 æ ¸å¿ƒé€»è¾‘] 
    L1 = 1-hopé—®é¢˜ (æ ¸å¿ƒéªŒè¯å¯¹è±¡)
    L0 = åŸºç¡€é—®é¢˜
    """
    return {
        "L1": next((q["question"] for q in q_chain if q.get("level") == 1), ""),
        "L0": next((q["question"] for q in q_chain if q.get("level") == 0), "")
    }

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 1: å±€éƒ¨é‡å¤é¢„æ£€ (Q-Only, History-Only)
# ==========================================

def pre_check_duplication(new_data: List[Dict[str, Any]], 
                          history_file: str = None, 
                          sample_size: int = 100, 
                          match_threshold: int = 10) -> bool:
    """
    ä¸ 2-hop ä»£ç ä¿æŒä¸€è‡´ï¼š
    1. åªæ£€æŸ¥ history_fileã€‚
    2. åªæ¯”å¯¹ L1 Question æ–‡æœ¬ã€‚
    """
    
    if not history_file or not os.path.exists(history_file):
        return False

    if not new_data: return False

    # --- æ­¥éª¤ A: ç”ŸæˆæŒ‡çº¹ (éšæœºæŠ½æ ·, åªå– L1 Question) ---
    real_sample_size = min(len(new_data), sample_size)
    sample_records = random.sample(new_data, real_sample_size)
    
    pending_fingerprints = set()
    
    for item in sample_records:
        qs = extract_questions_1hop(item.get("Q_chain", []))
        q_text = qs.get("L1", "").strip() # è¿™é‡Œå– L1
        if q_text:
            pending_fingerprints.add(q_text)
            
    if not pending_fingerprints: return False

    current_threshold = min(match_threshold, len(pending_fingerprints))

    print(f"ğŸ” [Pre-Check] æ­£åœ¨æ‰«æå†å²æ–‡ä»¶ [{os.path.basename(history_file)}] ...")
    print(f"   - é‡‡æ ·æŒ‡çº¹(Q only): {len(pending_fingerprints)} æ¡")
    print(f"   - åˆ¤å®šé˜ˆå€¼: å‘½ä¸­ >= {current_threshold} æ¡å³è§†ä¸ºé‡å¤")

    match_count = 0

    # --- æ­¥éª¤ B: æ‰«æå†å²æ–‡ä»¶ ---
    try:
        with open(history_file, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip(): continue
                try:
                    existing = json.loads(line)
                    ex_q = existing.get("question", "").strip()
                    if not ex_q: continue

                    if ex_q in pending_fingerprints:
                        match_count += 1
                        pending_fingerprints.remove(ex_q)
                        
                        if match_count >= current_threshold:
                            print(f"â­ï¸  [Duplicate] å‘½ä¸­æ¬¡æ•°è¾¾åˆ° {match_count}ï¼Œåˆ¤å®šä»»åŠ¡å·²è¿è¡Œè¿‡ã€‚")
                            return True 
                except:
                    continue
    except Exception as e:
        print(f"âš ï¸  [Pre-Check] è¯»å–æ–‡ä»¶ {history_file} å‡ºé”™: {e}ï¼Œè·³è¿‡æ£€æŸ¥")
        return False

    print(f"   [Pre-Check] æœ€ç»ˆå‘½ä¸­: {match_count}/{current_threshold}ã€‚æœªè¾¾åˆ°é˜ˆå€¼ï¼Œè§†ä¸ºæ–°ä»»åŠ¡ã€‚")
    return False

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 2: Prompt æ„å»º (L1 éªŒè¯)
# ==========================================

def construct_1hop_validation_prompt(qs: Dict[str, str], bridge: str) -> str:
    """
    [ä¿æŒä¸å˜] éªŒè¯ L1 æ˜¯å¦å”¯ä¸€æŒ‡ä»£ Bridge
    """
    return f"""# Role
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„é€»è¾‘æ£€æŸ¥å‘˜ã€‚æˆ‘ä»¬éœ€è¦éªŒè¯ä¸€ä¸ªå•è·³é—®ç­”æ¨ç†é“¾æ¡ä¸­çš„æŒ‡ä»£æ˜¯å¦**ç²¾å‡†ä¸”å”¯ä¸€**ã€‚

# Context
æˆ‘ä»¬æœ‰ä¸¤å±‚é—®é¢˜ (L0 -> L1) å’Œä¸€ä¸ªè¿æ¥å®ƒä»¬çš„â€œæ¡¥æ¢å®ä½“â€ã€‚
- **L0 (åŸºç¡€é—®é¢˜)**: {qs['L0']}
- **L1 (1-hopé—®é¢˜)**: {qs['L1']}

# Bridge Entity
- **Bridge**: {bridge}

# Task
è¯·**ä¸€æ­¥æ­¥æ€è€ƒ**ï¼Œæ£€æŸ¥ä¸‹é¢çš„é€»è¾‘è¿æ¥æ˜¯å¦æœ‰æ•ˆï¼š

**Check (L1 vs L0)**: L1 ä¸­å¤šå‡ºçš„æè¿°ï¼ˆç›¸è¾ƒäº L0ï¼‰æ˜¯å¦**å”¯ä¸€**åœ°æŒ‡ä»£äº† `Bridge` å®ä½“ï¼Ÿ

# Criteria 
- **åˆæ ¼ (true)**: 
  - æè¿°å…·æœ‰å”¯ä¸€æŒ‡å‘æ€§ï¼ˆå¦‚â€œ...çš„é¦–åºœâ€ã€â€œ...çš„å¯¼æ¼”â€ã€â€œ...çš„å‡ºç”Ÿå¹´ä»½â€ï¼‰ã€‚
  - å…è®¸æªè¾çš„ç»†å¾®å˜åŒ–ï¼ˆå¦‚â€œæ‰§å¯¼çš„äººâ€vsâ€œå¯¼æ¼”â€ï¼‰ã€‚
  - å¦‚æœä½ çš„åˆ¤æ–­æ˜¯** L1ä¸­æ²¡æœ‰æåˆ°xxxï¼Œå› æ­¤æ— æ³•å”¯ä¸€æŒ‡ä»£Bridge **ï¼Œå¦‚æœL1æŒ‡å‘æ²¡æœ‰ç®€å•çš„æ­§ä¹‰ï¼Œä»ç„¶åˆ¤æ–­ä¸ºåˆæ ¼ã€‚
  - å¤–éƒ¨ä¿¡æ¯å¯¼è‡´ï¼Œæè¿°æ˜¯ä¸€ä¸ªæŒ‡å‘å”¯ä¸€ç¡®å®šçš„åè¯ï¼Œé»˜è®¤èƒ½æ­£ç¡®æŒ‡å‘å¯¹åº”çš„Bridgeã€‚
- **ä¸åˆæ ¼ (false)**: 
  - ** æ¨¡ç³ŠæŒ‡ä»£**: åªæœ‰â€œ...ä¹‹ä¸€â€ã€â€œ...çš„ä¸€ä¸ªåŸå¸‚â€ã€â€œ...çš„æˆå‘˜â€ã€â€œ...çš„ä¸€éƒ¨åˆ†â€ã€‚
  - ** é€»è¾‘é”™è¯¯**: æè¿°å®Œå…¨é”™è¯¯ã€‚
  - ** åŸåœ°æŒ‡ä»£**: ç”¨äº†ä¸ä¹‹å‰å­—è¯é«˜åº¦ç›¸ä¼¼çš„æè¿°ï¼ˆä¾‹å¦‚ L0 é—®â€œXåœ¨å“ªé‡Œâ€ï¼ŒL1 é—®â€œXçš„ä½ç½®åœ¨å“ªé‡Œâ€ï¼Œæ²¡æœ‰å®è´¨æ›¿æ¢ï¼‰ã€‚
  - ** æ³¨æ„: åªæœ‰åœ¨æ˜æ˜¾æŒ‡ä»£æœ‰æ­§ä¹‰ï¼Œæˆ–è€…æ˜æ˜¾æœ‰é”™è¯¯æ—¶æ‰è¾“å‡ºfalseã€‚
  
# Output Format (JSON Only)
ä¸è¦è¾“å‡ºä»»ä½•é—²èŠï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œå¿…é¡»åŒ…å« valid å­—æ®µï¼š
```json
{{
  "reason": "ç®€çŸ­åˆ†æL1å¯¹Bridgeçš„æŒ‡ä»£æƒ…å†µ...",
  "valid": true/false
}}
```"""

async def call_llm_json(session, url, model_name, prompt):
    try:
        payload = {
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 512,
            "temperature": 0.1,
            "response_format": {"type": "json_object"}
        }
        async with session.post(url, json=payload, timeout=60) as response:
            if response.status == 200:
                result = await response.json()
                content = result['choices'][0]['message']['content'].strip()
                if content.startswith('```json'):
                    content = content.replace('```json', '').replace('```', '')
                try:
                    return json.loads(content)
                except:
                    match = re.search(r'\{.*\}', content, re.DOTALL)
                    return json.loads(match.group(0)) if match else None
            return None
    except Exception:
        return None

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 3: å†™å…¥å™¨ (Writer) - æ ¼å¼å·²ç»Ÿä¸€
# ==========================================

async def result_writer_service(queue: asyncio.Queue, file_paths: Dict[str, str], source_name: str):
    f_valid_q = open(file_paths["questions"], 'a+', encoding='utf-8')
    f_valid_r = open(file_paths["references"], 'a+', encoding='utf-8')
    f_invalid = open(file_paths["invalid"], 'a+', encoding='utf-8')

    valid_count = 0
    invalid_count = 0

    try:
        while True:
            item = await queue.get()
            if item is None:
                queue.task_done()
                break

            qs = extract_questions_1hop(item.get("Q_chain", []))
            
            if item.get("_is_valid_llm", False):
                valid_count += 1
                context = item.get("context", {})
                doc_ref_ids = []
                
                # [Format Update] ç»Ÿä¸€éå† document1, document2ï¼Œå¹¶è®°å½• document_id
                # 1-hop é€šå¸¸æ¶‰åŠ R1, R2
                for dk, rk, rt in [("document1", "R1", "R1"), ("document2", "R2", "R2")]:
                    raw_content = context.get(rk)
                    if not raw_content: continue
                    
                    # å…¼å®¹ list æˆ– str
                    val = raw_content[0] if isinstance(raw_content, list) and len(raw_content) > 0 else str(raw_content)
                    
                    doc_meta = context.get(dk, {})
                    title = doc_meta.get("title", "").strip()
                    doc_id = doc_meta.get("id", "") # è·å– document_id
                    
                    full_val = f"{title}\n{val}" if title else val

                    ref_uuid = str(uuid.uuid4())
                    ref_record = {
                        "id": ref_uuid,
                        "value": full_val,
                        "meta_data": {
                            "r_type": rt,
                            "document_id": doc_id,    # [ç»Ÿä¸€]
                            "document_title": title,  # [ç»Ÿä¸€]
                            "original_data_source": source_name
                        }
                    }
                    json.dump(ref_record, f_valid_r, ensure_ascii=False)
                    f_valid_r.write('\n')
                    doc_ref_ids.append(ref_uuid)

                # [Format Update] ç»Ÿä¸€ connection ç»“æ„
                def fmt_conn(key):
                    c = context.get(key, {})
                    res = {}
                    if "bridge" in c: res["bridge"] = c["bridge"]
                    if "similarity" in c:
                        try: res["similarity"] = round(float(c["similarity"]), 2)
                        except: res["similarity"] = c["similarity"]
                    return res

                q_record = {
                    "answer": item["A"],
                    "question": qs["L1"], # 1-hop çš„é¡¶å±‚é—®é¢˜æ˜¯ L1
                    "label": doc_ref_ids,
                    "meta_data": {
                        # 1-hop åªæœ‰ d1-d2 çš„è¿æ¥
                        "connection_d1_d2": fmt_conn("connection_d1_d2"), 
                        "question_level_0": qs["L0"], # [ç»Ÿä¸€] é‡å‘½åä¸º question_level_0
                        "original_data_source": source_name
                    }
                }
                json.dump(q_record, f_valid_q, ensure_ascii=False, separators=(',', ':'))
                f_valid_q.write('\n')
                
            else:
                invalid_count += 1
                simple_record = {
                    "question": qs["L1"], 
                    "question_level_0": qs["L0"],
                    "answer": item.get("A", ""),
                    "invalid_reason": item.get("_llm_reason", "LLM Check Failed")
                }
                json.dump(simple_record, f_invalid, ensure_ascii=False)
                f_invalid.write('\n')

            queue.task_done()
            if (valid_count + invalid_count) % 10 == 0:
                f_valid_q.flush()
                f_valid_r.flush()
                f_invalid.flush()

    finally:
        f_valid_q.close()
        f_valid_r.close()
        f_invalid.close()
        print(f"\nğŸ“Š å†™å…¥å®Œæˆ: æœ‰æ•ˆ {valid_count} æ¡, æ— æ•ˆ {invalid_count} æ¡")

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 4: Worker
# ==========================================

async def worker(session, url, model_name, item, semaphore, queue):
    q_chain = item.get("Q_chain", [])
    qs = extract_questions_1hop(q_chain)
    context = item.get("context", {})
    target_bridge = context.get("connection_d1_d2", {}).get("bridge", None)

    is_valid = False
    reason = "Data Missing"

    # [éªŒè¯é€»è¾‘] L1, L0, Bridge å¿…é¡»éƒ½å­˜åœ¨
    if qs["L1"] and qs["L0"] and target_bridge:
        prompt = construct_1hop_validation_prompt(qs, target_bridge)
        async with semaphore:
            result_json = await call_llm_json(session, url, model_name, prompt)
            if result_json:
                def check_bool(val):
                    if isinstance(val, bool): return val
                    if isinstance(val, str): return val.lower() == 'true'
                    return False
                is_valid = check_bool(result_json.get("valid", False))
                reason = result_json.get("reason", "Passed" if is_valid else "Unknown")
            else:
                reason = "LLM JSON Error"
    
    item["_is_valid_llm"] = is_valid
    item["_llm_reason"] = reason
    await queue.put(item)

# ==========================================
# ä¸»æµç¨‹å…¥å£
# ==========================================

async def main_pipeline(args):
    try:
        source_name = args.input.split('/')[-2]
    except:
        source_name = "unknown"
    
    print(f"ğŸ“„ åŠ è½½æ•°æ®: {args.input}")
    data = load_original_data(args.input)
    if not data: return

    # [ç»Ÿä¸€] ä½¿ç”¨å‡çº§ç‰ˆçš„ pre_check
    if pre_check_duplication(data, 
                             history_file=args.history_file, 
                             sample_size=100, 
                             match_threshold=5):
        print(f"â­ï¸  [Skip] æ•°æ®å·²åœ¨å†å²æ–‡ä»¶ [{args.history_file}] ä¸­æ£€æµ‹åˆ°ï¼Œè·³è¿‡å¤„ç†ã€‚")
        return

    # åŸºç¡€è¿‡æ»¤ï¼šå¿…é¡»æœ‰ L1
    print("æ­¥éª¤ 1/2: åŸºç¡€è¿‡æ»¤ (L1 Check)...")
    candidates = []
    for item in data:
        qs = extract_questions_1hop(item.get("Q_chain", []))
        if qs["L1"] and item.get("A"):
            candidates.append(item)
            
    print(f"å¾…æ ¡éªŒæ•°æ®: {len(candidates)} æ¡")
    if not candidates: return

    print(f"æ­¥éª¤ 2/2: LLM æ ¡éªŒ...")
    queue = asyncio.Queue()
    file_paths = {
        "questions": args.output_questions,
        "references": args.output_references,
        "invalid": args.output_invalid
    }

    writer_task = asyncio.create_task(
        result_writer_service(queue, file_paths, source_name)
    )

    semaphore = asyncio.Semaphore(args.concurrency)
    async with aiohttp.ClientSession() as session:
        tasks = [asyncio.create_task(worker(session, args.api_url, args.model_name, i, semaphore, queue)) for i in candidates]
        for f in tqdm.as_completed(tasks):
            await f

    await queue.put(None)
    await writer_task
    print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--output-questions", required=True)
    parser.add_argument("--output-references", required=True)
    parser.add_argument("--output-invalid", required=True)
    parser.add_argument("--api-url", default="http://localhost:8111/v1/chat/completions")
    parser.add_argument("--model-name", default="qwen")
    parser.add_argument("--concurrency", type=int, default=64)
    # [ç»Ÿä¸€] å‚æ•°å‘½åä¿æŒä¸€è‡´
    parser.add_argument("--history-file", default=None, help="ä»…ç”¨äºå»é‡æ£€æŸ¥çš„å…¨å±€å†å²æ–‡ä»¶ (.jsonl)")
    args = parser.parse_args()

    try:
        asyncio.run(main_pipeline(args))
    except KeyboardInterrupt:
        print("\nâ›” ç”¨æˆ·ä¸­æ–­ã€‚")

if __name__ == "__main__":
    main()