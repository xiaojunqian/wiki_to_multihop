import json
import argparse
import os
import random
import asyncio
import aiohttp
import re
import uuid
import sys
from typing import List, Dict, Any, Optional
from tqdm.asyncio import tqdm

# ==========================================
# åŸºç¡€å·¥å…·æ¨¡å—
# ==========================================

def load_original_data(input_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½åŸå§‹æ•°æ® (JSONL)"""
    data = []
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and line.startswith('{'):
                    try:
                        data.append(json.loads(line))
                    except:
                        pass
        return data
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {input_path}")
        return []

def save_lines_append(file_path: str, data_list: List[Dict[str, Any]]):
    """é€šç”¨è¿½åŠ å†™å…¥å·¥å…·"""
    if not data_list:
        return
    with open(file_path, 'a+', encoding='utf-8') as f:
        for item in data_list:
            json.dump(item, f, ensure_ascii=False)
            f.write('\n')

def extract_questions(q_chain: List[Dict[str, Any]]) -> Dict[str, str]:
    """è¾…åŠ©å‡½æ•°ï¼šæå– L2, L1, L0 é—®é¢˜"""
    return {
        "L2": next((q["question"] for q in q_chain if q.get("level") == 2), ""),
        "L1": next((q["question"] for q in q_chain if q.get("level") == 1), ""),
        "L0": next((q["question"] for q in q_chain if q.get("level") == 0), "")
    }

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 1: å±€éƒ¨é‡å¤é¢„æ£€ (Q-Only, History-Only)
# ==========================================

def pre_check_duplication(new_data: List[Dict[str, Any]], 
                          history_file: str = None, 
                          sample_size: int = 100, 
                          match_threshold: int = 10) -> bool:
    """
    æ£€æŸ¥æ•°æ®æ˜¯å¦å·²å­˜åœ¨ã€‚
    ä¿®æ”¹ç‚¹ 1: åªæ£€æŸ¥ history_fileï¼Œä¸æ£€æŸ¥ current_outputã€‚
    ä¿®æ”¹ç‚¹ 2: åªæ¯”å¯¹ Questionï¼Œä¸æ¯”å¯¹ Answerã€‚
    """
    
    # å¦‚æœæ²¡æœ‰æä¾›å†å²æ–‡ä»¶ï¼Œæˆ–è€…å†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è®¤ä¸ºæ²¡è·‘è¿‡
    if not history_file or not os.path.exists(history_file):
        return False

    if not new_data: return False

    # --- æ­¥éª¤ A: ç”ŸæˆæŒ‡çº¹ (éšæœºæŠ½æ ·, åªå– Question) ---
    real_sample_size = min(len(new_data), sample_size)
    sample_records = random.sample(new_data, real_sample_size)
    
    # ä½¿ç”¨é›†åˆå­˜å‚¨å¾…æŸ¥æ‰¾çš„æŒ‡çº¹ï¼Œè¿™é‡Œåªå­˜ L2 Question å­—ç¬¦ä¸²
    pending_fingerprints = set()
    
    for item in sample_records:
        qs = extract_questions(item.get("Q_chain", []))
        q_text = qs.get("L2", "").strip()
        if q_text:
            pending_fingerprints.add(q_text)
            
    if not pending_fingerprints: return False

    # åŠ¨æ€è°ƒæ•´é˜ˆå€¼
    current_threshold = min(match_threshold, len(pending_fingerprints))

    print(f"ğŸ” [Pre-Check] æ­£åœ¨æ‰«æå†å²æ–‡ä»¶ [{os.path.basename(history_file)}] ...")
    print(f"   - é‡‡æ ·æŒ‡çº¹(Q only): {len(pending_fingerprints)} æ¡")
    print(f"   - åˆ¤å®šé˜ˆå€¼: å‘½ä¸­ >= {current_threshold} æ¡å³è§†ä¸ºé‡å¤")

    match_count = 0

    # --- æ­¥éª¤ B: æ‰«æå†å²æ–‡ä»¶ ---
    try:
        with open(history_file, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip(): continue
                try:
                    existing = json.loads(line)
                    # æå–å·²æœ‰æ•°æ®çš„ Question
                    ex_q = existing.get("question", "").strip()
                    
                    if not ex_q: continue

                    # æ£€æŸ¥æ˜¯å¦å‘½ä¸­ (åªæ¯”å¯¹ Q)
                    if ex_q in pending_fingerprints:
                        match_count += 1
                        # ç§»é™¤å·²å‘½ä¸­çš„ï¼Œé¿å…é‡å¤è®¡æ•°
                        pending_fingerprints.remove(ex_q)
                        
                        if match_count >= current_threshold:
                            print(f"â­ï¸  [Duplicate] å‘½ä¸­æ¬¡æ•°è¾¾åˆ° {match_count}ï¼Œåˆ¤å®šä»»åŠ¡å·²è¿è¡Œè¿‡ã€‚")
                            return True 
                except:
                    continue
    except Exception as e:
        print(f"âš ï¸  [Pre-Check] è¯»å–æ–‡ä»¶ {history_file} å‡ºé”™: {e}ï¼Œè·³è¿‡æ£€æŸ¥")
        return False

    print(f"   [Pre-Check] æœ€ç»ˆå‘½ä¸­: {match_count}/{current_threshold}ã€‚æœªè¾¾åˆ°é˜ˆå€¼ï¼Œè§†ä¸ºæ–°ä»»åŠ¡ã€‚")
    return False

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 2: Prompt æ„å»º
# ==========================================

def construct_substitution_check_prompt(complex_q: str, simple_q: str, bridge_entity: str, ref_text: str) -> str:
    return f"""# Role
ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥æ ¼çš„é€»è¾‘æ ¡éªŒä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æªå‡ºå¤šè·³é—®ç­”ä¸­**å…·æœ‰æ­§ä¹‰**çš„å®ä½“æ›¿æ¢ã€‚

# Context
æˆ‘ä»¬é€šè¿‡å°†â€œç®€å•é—®é¢˜â€ä¸­çš„ [Bridge Entity] æ›¿æ¢ä¸ºä¸€æ®µæè¿°ï¼Œç”Ÿæˆäº†â€œå¤æ‚é—®é¢˜â€ã€‚
æˆ‘ä»¬éœ€è¦ç¡®ä¿ï¼šè¿™æ®µæè¿°åœ¨ç»“åˆ [Reference Text] åï¼Œ**åªèƒ½**æŒ‡å‘ [Bridge Entity]ï¼Œè€Œä¸èƒ½æŒ‡å‘å…¶ä»–äººæˆ–ç‰©ã€‚

# Data
1. **Complex Question**: "{complex_q}"
2. **Simple Question**: "{simple_q}"
3. **Bridge Entity**: "{bridge_entity}"
4. **Reference Text**: 
   "{ref_text}"

# Critical Instructions

1. **Step 1: Extract Phrase**
   æ‰¾å‡º Complex Question ä¸­ç”¨æ¥æŒ‡ä»£ Bridge Entity çš„æè¿°çŸ­è¯­ã€‚

2. **Step 2: Verify Factuality**
   éªŒè¯æè¿°æ˜¯å¦ç¬¦åˆäº‹å®ã€‚

3. **Step 3: Check Uniqueness (æ’ä»–æ€§æ£€æŸ¥)**
   æ£€æŸ¥åŸæ–‡ä¸­æ˜¯å¦æœ‰**å…¶ä»–å®ä½“**ä¹Ÿç¬¦åˆè¯¥æè¿°ã€‚å¦‚æœåŸæ–‡åˆ—ä¸¾äº†å¤šä¸ªåŒç±»é¡¹ï¼Œä¸”æè¿°æ— æ³•å”¯ä¸€é”å®šç›®æ ‡ï¼Œå¿…é¡»åˆ¤ä¸º Falseã€‚

# Output Format (JSON Only)
```json
{{
  "diff_phrase": "...",
  "analysis": "...",
  "valid": true/false
}}
```"""

async def call_llm_json(session, url, model_name, prompt):
    try:
        payload = {
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 512,
            "temperature": 0.0,
            "response_format": {"type": "json_object"}
        }
        async with session.post(url, json=payload) as response:
            if response.status == 200:
                result = await response.json()
                content = result['choices'][0]['message']['content'].strip()
                try:
                    return json.loads(content)
                except json.JSONDecodeError:
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        return json.loads(json_match.group(0))
                    else:
                        return None
            return None
    except Exception:
        return None

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 3: æµå¼å†™å…¥å™¨
# ==========================================

async def result_writer_service(queue: asyncio.Queue, file_paths: Dict[str, str], source_name: str):
    f_valid_q = open(file_paths["questions"], 'a+', encoding='utf-8')
    f_valid_r = open(file_paths["references"], 'a+', encoding='utf-8')
    f_invalid = open(file_paths["invalid"], 'a+', encoding='utf-8')

    valid_count = 0
    invalid_count = 0

    try:
        while True:
            item = await queue.get()
            if item is None:
                queue.task_done()
                break

            qs = extract_questions(item.get("Q_chain", []))
            
            if item.get("_is_valid_llm", False):
                valid_count += 1
                context = item["context"]
                doc_ref_ids = []
                
                for dk, rk, rt in [("document1", "R1", "R1"), ("document2", "R2", "R2"), ("document3", "R3", "R3")]:
                    title = context.get(dk, {}).get("title", "").strip()
                    raw = context[rk][0] if isinstance(context[rk], list) else str(context[rk])
                    val = f"{title}\n{raw}" if title else raw
                    
                    ref_uuid = str(uuid.uuid4())
                    ref_record = {
                        "id": ref_uuid,
                        "value": val,
                        "meta_data": {
                            "r_type": rt,
                            "document_id": context.get(dk, {}).get("id", ""),
                            "document_title": title,
                            "original_data_source": source_name
                        }
                    }
                    json.dump(ref_record, f_valid_r, ensure_ascii=False)
                    f_valid_r.write('\n')
                    doc_ref_ids.append(ref_uuid)

                def fmt_conn(key):
                    c = context.get(key, {})
                    res = {}
                    if "bridge" in c: res["bridge"] = c["bridge"]
                    if "similarity" in c:
                        try: res["similarity"] = round(float(c["similarity"]), 2)
                        except: res["similarity"] = c["similarity"]
                    return res

                q_record = {
                    "answer": item["A"],
                    "question": qs["L2"],
                    "label": doc_ref_ids,
                    "meta_data": {
                        "connection_d1_d2": fmt_conn("connection_d1_d2"),
                        "connection_d2_d3": fmt_conn("connection_d2_d3"),
                        "question_level_1": qs["L1"],
                        "question_level_0": qs["L0"],
                        "original_data_source": source_name
                    }
                }
                json.dump(q_record, f_valid_q, ensure_ascii=False, separators=(',', ':'))
                f_valid_q.write('\n')
                
            else:
                invalid_count += 1
                simple_record = {
                    "question": qs["L2"],
                    "question_level_1": qs["L1"],
                    "question_level_0": qs["L0"],
                    "answer": item.get("A", ""),
                    "invalid_reason": item.get("_llm_reason", "LLM Check Failed")
                }
                json.dump(simple_record, f_invalid, ensure_ascii=False)
                f_invalid.write('\n')

            queue.task_done()
            if (valid_count + invalid_count) % 10 == 0:
                f_valid_q.flush()
                f_valid_r.flush()
                f_invalid.flush()

    finally:
        f_valid_q.close()
        f_valid_r.close()
        f_invalid.close()
        print(f"\nğŸ“Š å†™å…¥å®Œæˆ: æœ‰æ•ˆ {valid_count} æ¡, æ— æ•ˆ {invalid_count} æ¡")

# ==========================================
# ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ 4: ç”Ÿäº§è€… Worker
# ==========================================

def get_doc_text(context, doc_key, content_key):
    try:
        title = context.get(doc_key, {}).get("title", "")
        content_raw = context.get(content_key, "")
        if isinstance(content_raw, list):
            content_raw = " ".join(content_raw)
        return f"Title: {title}\nContent: {content_raw}"
    except:
        return ""

async def worker(session, url, model_name, item, semaphore, queue):
    q_chain = item.get("Q_chain", [])
    qs = extract_questions(q_chain)
    context = item.get("context", {})
    
    bridge_2 = context.get("connection_d2_d3", {}).get("bridge", None)
    bridge_1 = context.get("connection_d1_d2", {}).get("bridge", None)
    
    ref_text_step_1 = get_doc_text(context, "document2", "R2")
    ref_text_step_2 = get_doc_text(context, "document1", "R1")

    is_valid = False
    reason = "Data Missing"

    if qs["L2"] and qs["L1"] and qs["L0"] and bridge_1 and bridge_2 and ref_text_step_1 and ref_text_step_2:
        async with semaphore:
            # Step 1
            prompt_step_1 = construct_substitution_check_prompt(
                complex_q=qs["L1"], 
                simple_q=qs["L0"], 
                bridge_entity=bridge_2,
                ref_text=ref_text_step_1
            )
            res_1 = await call_llm_json(session, url, model_name, prompt_step_1)
            
            valid_1 = False
            reason_1 = "LLM Error (Step 1)"
            if res_1:
                val = res_1.get("valid", False)
                if isinstance(val, bool): valid_1 = val
                elif isinstance(val, str): valid_1 = val.lower() == 'true'
                reason_1 = f"[{res_1.get('diff_phrase')}] {res_1.get('analysis')}"

            if not valid_1:
                is_valid = False
                reason = f"Step1 Fail: {reason_1}"
            else:
                # Step 2
                prompt_step_2 = construct_substitution_check_prompt(
                    complex_q=qs["L2"], 
                    simple_q=qs["L1"], 
                    bridge_entity=bridge_1,
                    ref_text=ref_text_step_2
                )
                res_2 = await call_llm_json(session, url, model_name, prompt_step_2)
                
                valid_2 = False
                reason_2 = "LLM Error (Step 2)"
                if res_2:
                    val = res_2.get("valid", False)
                    if isinstance(val, bool): valid_2 = val
                    elif isinstance(val, str): valid_2 = val.lower() == 'true'
                    reason_2 = f"[{res_2.get('diff_phrase')}] {res_2.get('analysis')}"
                
                if valid_2:
                    is_valid = True
                    reason = "Passed Both Steps"
                else:
                    is_valid = False
                    reason = f"Step2 Fail: {reason_2}"

    item["_is_valid_llm"] = is_valid
    item["_llm_reason"] = reason
    await queue.put(item)

# ==========================================
# ä¸»æµç¨‹å…¥å£
# ==========================================

async def main_pipeline(args):
    try:
        source_name = args.input.split('/')[-2]
    except:
        source_name = "unknown"
    
    print(f"ğŸ“„ åŠ è½½æ•°æ®: {args.input}")
    data = load_original_data(args.input)
    if not data: return

    # === [UPDATE] å»é‡æ£€æŸ¥ ===
    # åªæ£€æŸ¥ history_fileï¼Œåªæ¯”å¯¹ Qï¼Œä¸æ£€æŸ¥ current_output
    if pre_check_duplication(data, 
                             history_file=args.history_file, 
                             sample_size=100, 
                             match_threshold=5):
        print(f"â­ï¸  [Skip] æ•°æ®å·²åœ¨å†å²æ–‡ä»¶ [{args.history_file}] ä¸­æ£€æµ‹åˆ°ï¼Œè·³è¿‡å¤„ç†ã€‚")
        return

    # åŸºç¡€è¿‡æ»¤
    print("æ­¥éª¤ 1/2: åŸºç¡€è¿‡æ»¤ (Answer Leakage)...")
    candidates = []
    invalid_step1 = []
    
    for item in data:
        ans = item.get("A", "").strip()
        qs = extract_questions(item.get("Q_chain", []))
        leaked = False
        for q_txt in qs.values():
            if ans in q_txt:
                leaked = True; break
        
        if not leaked:
            candidates.append(item)
        else:
            invalid_step1.append({
                "question": qs["L2"], "answer": ans, "invalid_reason": "Answer Leakage"
            })
            
    if invalid_step1:
        save_lines_append(args.output_invalid, invalid_step1)
    
    print(f"å¾… vLLM æ ¡éªŒæ•°æ®: {len(candidates)} æ¡")
    if not candidates: return

    # å¯åŠ¨å¤„ç†
    print(f"æ­¥éª¤ 2/2: vLLM åˆ†æ­¥æ ¡éªŒ...")
    queue = asyncio.Queue()
    writer_task = asyncio.create_task(result_writer_service(queue, {
        "questions": args.output_questions,
        "references": args.output_references,
        "invalid": args.output_invalid
    }, source_name))

    semaphore = asyncio.Semaphore(args.concurrency)
    async with aiohttp.ClientSession() as session:
        tasks = [asyncio.create_task(worker(session, args.api_url, args.model_name, item, semaphore, queue)) for item in candidates]
        for f in tqdm.as_completed(tasks): await f

    await queue.put(None)
    await writer_task
    print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--output-questions", required=True)
    parser.add_argument("--output-references", required=True)
    parser.add_argument("--output-invalid", required=True)
    parser.add_argument("--api-url", default="http://localhost:8111/v1/chat/completions")
    parser.add_argument("--model-name", default="qwen")
    parser.add_argument("--concurrency", type=int, default=64)
    # === [UPDATE] æ–°å¢å‚æ•° ===
    parser.add_argument("--history-file", default=None, help="ä»…ç”¨äºå»é‡æ£€æŸ¥çš„å…¨å±€å†å²æ–‡ä»¶ (.jsonl)")
    args = parser.parse_args()

    try:
        asyncio.run(main_pipeline(args))
    except KeyboardInterrupt:
        print("\nâ›” ç”¨æˆ·ä¸­æ–­ã€‚")

if __name__ == "__main__":
    main()