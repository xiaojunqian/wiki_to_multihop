import json
import argparse
import os
import random
from typing import List, Dict, Any, Optional

def load_original_data(input_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½JSONLæ ¼å¼åŸå§‹æ•°æ®ï¼Œè¿‡æ»¤æ— æ•ˆè¡Œï¼ˆéå¤§æ‹¬å·èµ·å§‹ã€è§£æå¤±è´¥ã€å­—æ®µç¼ºå¤±ï¼‰"""
    original_data = []
    valid_lines = 0
    invalid_lines = 0

    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                cleaned_line = line.strip()
                
                # è¿‡æ»¤ç©ºè¡Œ
                if not cleaned_line:
                    invalid_lines += 1
                    continue
                
                # è¿‡æ»¤éå¤§æ‹¬å·èµ·å§‹çš„è¡Œ
                if not cleaned_line.startswith('{'):
                    print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡Œéå¤§æ‹¬å·èµ·å§‹ï¼Œå·²å¿½ç•¥ -> å†…å®¹ï¼š{cleaned_line[:50]}...")
                    invalid_lines += 1
                    continue
                
                # è§£æJSON
                try:
                    data_item = json.loads(cleaned_line)
                except json.JSONDecodeError as e:
                    print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡ŒJSONæ ¼å¼é”™è¯¯ï¼Œå·²å¿½ç•¥ -> é”™è¯¯ï¼š{str(e)[:50]}")
                    invalid_lines += 1
                    continue
                
                # æ ¡éªŒå¿…è¦å­—æ®µ
                required_fields = ["A", "Q_chain", "context"]
                if not all(field in data_item for field in required_fields):
                    print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡Œç¼ºå¤±å¿…è¦å­—æ®µï¼ˆA/Q_chain/contextï¼‰ï¼Œå·²å¿½ç•¥")
                    invalid_lines += 1
                    continue
                
                # æ ¡éªŒcontextä¸­çš„å¿…è¦å­—æ®µ
                context = data_item["context"]
                required_context_fields = ["R1", "R2", "R3", "connection_d1_d2", "connection_d2_d3"]
                if not all(field in context for field in required_context_fields):
                    print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡Œcontextç¼ºå¤±å¿…è¦å­—æ®µï¼ˆR1/R2/R3/connection_d1_d2/connection_d2_d3ï¼‰ï¼Œå·²å¿½ç•¥")
                    invalid_lines += 1
                    continue
                
                original_data.append(data_item)
                valid_lines += 1

        print(f"\næ•°æ®åŠ è½½å®Œæˆï¼š")
        print(f"- æ€»è¡Œæ•°ï¼š{line_num}")
        print(f"- æœ‰æ•ˆè¡Œæ•°ï¼ˆåŸºç¡€è¿‡æ»¤åï¼‰ï¼š{valid_lines}")
        print(f"- æ— æ•ˆè¡Œæ•°ï¼ˆæ ¼å¼/å­—æ®µé—®é¢˜ï¼‰ï¼š{invalid_lines}")
        return original_data

    except FileNotFoundError:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_path}")
    except Exception as e:
        raise RuntimeError(f"åŠ è½½æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{str(e)}")

def is_answer_in_question(answer: str, question: str) -> bool:
    """åˆ¤æ–­answeræ˜¯å¦å®Œæ•´å‡ºç°åœ¨questionä¸­ï¼ˆå»å‰åç©ºæ ¼ååŒ¹é…ï¼‰"""
    if not answer or not question:
        return False  # ä»»ä¸€ä¸ºç©ºï¼Œä¸è§†ä¸ºåŒ¹é…
    # å»å‰åç©ºæ ¼ååˆ¤æ–­å­ä¸²åŒ…å«ï¼ˆå®Œæ•´å‡ºç°ï¼‰
    clean_answer = answer.strip()
    clean_question = question.strip()
    return clean_answer in clean_question

def filter_invalid_data(original_data: List[Dict[str, Any]]) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼šanswerå®Œæ•´å‡ºç°åœ¨questionä¸­çš„æ•°æ®
    è¿”å›ï¼š(æœ‰æ•ˆæ•°æ®åˆ—è¡¨, æ— æ•ˆæ•°æ®åˆ—è¡¨)
    """
    filtered_data = []
    invalid_data = []

    for idx, item in enumerate(original_data, 1):
        # å…ˆæ‰¾åˆ°level2çš„questionï¼ˆä¸åç»­ç”ŸæˆQAçš„questionä¸€è‡´ï¼‰
        question = None
        for q in item["Q_chain"]:
            if q.get("level") == 2:
                question = q["question"]
                break
        
        if not question:
            # æ— level2 questionï¼ŒæŒ‰ä¹‹å‰é€»è¾‘è·³è¿‡ï¼Œä¸åŠ å…¥æ— æ•ˆæ•°æ®
            print(f"è­¦å‘Šï¼šç¬¬{idx}æ¡æ•°æ®æœªæ‰¾åˆ°level2çš„questionï¼Œå·²è·³è¿‡")
            continue
        
        answer = item.get("A", "").strip()
        # åˆ¤æ–­æ˜¯å¦æ»¡è¶³æ— æ•ˆæ¡ä»¶
        if is_answer_in_question(answer, question):
            # è®°å½•æ— æ•ˆåŸå› ï¼Œä¾¿äºè¿½æº¯
            item["invalid_reason"] = f"answer='{answer[:30]}...' å®Œæ•´å‡ºç°åœ¨ question='{question[:50]}...' ä¸­"
            item["invalid_data_source"] = input_path.split('/')[-2]  # è®°å½•æ•°æ®æ¥æº
            invalid_data.append(item)
            print(f"è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼šç¬¬{idx}æ¡ -> {item['invalid_reason']}")
        else:
            filtered_data.append(item)
    
    print(f"\næ•°æ®è¿‡æ»¤å®Œæˆï¼š")
    print(f"- è¿‡æ»¤åæœ‰æ•ˆæ•°æ®æ•°ï¼š{len(filtered_data)}")
    print(f"- æ— æ•ˆæ•°æ®æ•°ï¼ˆansweråœ¨questionä¸­ï¼‰ï¼š{len(invalid_data)}")
    return filtered_data, invalid_data

def save_invalid_data(invalid_data: List[Dict[str, Any]], invalid_output_path: str):
    """ä¿å­˜æ— æ•ˆæ•°æ®åˆ°ç‹¬ç«‹JSONLæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰"""
    if not invalid_data:
        return
    
    # è¿½åŠ å†™å…¥JSONLæ ¼å¼
    with open(invalid_output_path, 'a+', encoding='utf-8') as f:
        for record in invalid_data:
            json.dump(record, f, ensure_ascii=False)
            f.write('\n')
    
    # ç»Ÿè®¡æ— æ•ˆæ–‡ä»¶æ€»è®°å½•æ•°
    total_invalid = sum(1 for line in open(invalid_output_path, 'r', encoding='utf-8') if line.strip())
    print(f"\næ— æ•ˆæ•°æ®å·²è¿½åŠ è‡³ï¼š{invalid_output_path}")
    print(f"æ— æ•ˆæ–‡ä»¶å½“å‰æ€»è®°å½•æ•°ï¼š{total_invalid}")

def get_max_existing_r_count(reference_path: str) -> int:
    """è¯»å–JSONLæ ¼å¼å‚è€ƒæ–‡ä»¶çš„æœ‰æ•ˆè¡Œæ•°ï¼ˆå³å·²æœ‰çš„Ræ€»æ•°ï¼‰ï¼Œä½œä¸ºèµ·å§‹ç¼–å·ä¾æ®"""
    max_count = 0
    if os.path.exists(reference_path):
        try:
            with open(reference_path, 'r', encoding='utf-8') as f:
                for line in f:
                    cleaned_line = line.strip()
                    if not cleaned_line:
                        continue
                    # éªŒè¯è¡Œæ˜¯å¦ä¸ºæœ‰æ•ˆJSONï¼ˆé¿å…ç»Ÿè®¡æ— æ•ˆè¡Œï¼‰
                    try:
                        json.loads(cleaned_line)
                        max_count += 1
                    except json.JSONDecodeError:
                        continue
            print(f"å‚è€ƒæ–‡ä»¶å·²å­˜åœ¨ {max_count} ä¸ªRè®°å½•ï¼ˆæœ€å¤§ç¼–å·ï¼š{max_count}ï¼‰")
        except Exception as e:
            print(f"è¯»å–å‚è€ƒæ–‡ä»¶å¤±è´¥ï¼š{str(e)}ï¼Œå°†ä»1å¼€å§‹åˆ†é…Rç¼–å·")
            max_count = 0
    else:
        print(f"å‚è€ƒæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä»1å¼€å§‹åˆ†é…Rç¼–å·")
    return max_count

def format_connection(connection: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¼å¼åŒ–connectionå­—æ®µï¼šç§»é™¤edit_distanceï¼Œsimilarityä¿ç•™ä¸¤ä½å°æ•°"""
    formatted = {}
    # ä¿ç•™bridgeå­—æ®µ
    if "bridge" in connection:
        formatted["bridge"] = connection["bridge"]
    # å¤„ç†similarityï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
    if "similarity" in connection:
        try:
            similarity = float(connection["similarity"])
            formatted["similarity"] = round(similarity, 2)
        except (ValueError, TypeError):
            formatted["similarity"] = connection["similarity"]  # ä¿ç•™åŸå§‹å€¼ï¼Œé¿å…æŠ¥é”™
    return formatted

def process_r_reference(original_data: List[Dict[str, Any]], start_r_id: int) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    å¤„ç†Ræ•°æ®å’Œç¼–å·åˆ†é…ï¼ˆä»start_r_idå¼€å§‹ï¼‰
    ä¿®æ”¹åŠŸèƒ½ï¼š
    1. åœ¨Rçš„valueå‰æ‹¼æ¥document_titleã€‚
    2. æå–level 0å’Œlevel 1çš„é—®é¢˜åˆ°meta_dataã€‚
    è¿”å›ï¼š(é—®é¢˜æ–‡ä»¶æ•°æ®, å‚è€ƒæ–‡ä»¶æ•°æ®)
    """
    current_new_r_id = start_r_id
    reference_records = []  # å­˜å‚¨JSONLæ ¼å¼çš„Rè®°å½•ï¼ˆvalue + meta_dataï¼‰
    data_r_mapping = []    # å­˜å‚¨æ¯æ¡æ•°æ®å¯¹åº”çš„Rç¼–å·åˆ—è¡¨

    for idx, item in enumerate(original_data):
        context = item["context"]
        r_ids = []  # æŒ‰R1â†’R2â†’R3é¡ºåºå­˜å‚¨å…¨å±€å”¯ä¸€ç¼–å·

        # è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆå¸¦æ ‡é¢˜çš„å†…å®¹
        def format_r_content(doc_key, r_key):
            doc_info = context.get(doc_key, {})
            title = doc_info.get("title", "").strip()
            
            raw_content = context[r_key][0] if context[r_key] and isinstance(context[r_key], list) else str(context[r_key])
            
            # å¦‚æœæœ‰æ ‡é¢˜ï¼Œæ‹¼æ¥ "æ ‡é¢˜\næ­£æ–‡"ï¼›å¦åˆ™åªè¿”å›æ­£æ–‡
            if title:
                return f"{title}\n{raw_content}", title, doc_info.get("id", "")
            else:
                return raw_content, title, doc_info.get("id", "")

        # --- å¤„ç†R1 (document1) ---
        r1_val, r1_title, r1_id = format_r_content("document1", "R1")
        r1_record = {
            "value": r1_val,
            "meta_data": {
                "r_type": "R1",
                "document_id": r1_id,
                "document_title": r1_title,
                "original_data_source": input_path.split('/')[-2]
            }
        }
        reference_records.append(r1_record)
        r_ids.append(current_new_r_id)
        current_new_r_id += 1

        # --- å¤„ç†R2 (document2) ---
        r2_val, r2_title, r2_id = format_r_content("document2", "R2")
        r2_record = {
            "value": r2_val,
            "meta_data": {
                "r_type": "R2",
                "document_id": r2_id,
                "document_title": r2_title,
                "original_data_source": input_path.split('/')[-2]
            }
        }
        reference_records.append(r2_record)
        r_ids.append(current_new_r_id)
        current_new_r_id += 1

        # --- å¤„ç†R3 (document3) ---
        r3_val, r3_title, r3_id = format_r_content("document3", "R3")
        r3_record = {
            "value": r3_val,
            "meta_data": {
                "r_type": "R3",
                "document_id": r3_id,
                "document_title": r3_title,
                "original_data_source": input_path.split('/')[-2]
            }
        }
        reference_records.append(r3_record)
        r_ids.append(current_new_r_id)
        current_new_r_id += 1

        data_r_mapping.append(r_ids)

    # ç”Ÿæˆé—®é¢˜æ–‡ä»¶æ•°æ®ï¼ˆanswer + question + label + meta_dataï¼‰
    questions_data = []
    for idx, item in enumerate(original_data):
        # éå† Q_chain è·å–å„å±‚çº§é—®é¢˜
        question_lvl_2 = None
        question_lvl_1 = None
        question_lvl_0 = None
        
        for q in item["Q_chain"]:
            level = q.get("level")
            if level == 2:
                question_lvl_2 = q["question"]
            elif level == 1:
                question_lvl_1 = q["question"]
            elif level == 0:
                question_lvl_0 = q["question"]
        
        # å¦‚æœæ²¡æœ‰level 2é—®é¢˜ï¼Œè§†ä¸ºæ— æ•ˆ
        if not question_lvl_2:
            print(f"è­¦å‘Šï¼šç¬¬{idx+1}æ¡æœ‰æ•ˆæ•°æ®æœªæ‰¾åˆ°level=2çš„questionï¼Œå·²è·³è¿‡")
            continue
        
        # æå–å¹¶æ ¼å¼åŒ–connectionå­—æ®µ
        context = item["context"]
        connection_d1_d2 = format_connection(context.get("connection_d1_d2", {}))
        connection_d2_d3 = format_connection(context.get("connection_d2_d3", {}))
        
        questions_data.append({
            "answer": item["A"],          # A â†’ answer
            "question": question_lvl_2,   # level2_question â†’ question
            "label": data_r_mapping[idx],  # åˆ—è¡¨æ ¼å¼ï¼Œä¸æ¢è¡Œ
            "meta_data": {
                "connection_d1_d2": connection_d1_d2,
                "connection_d2_d3": connection_d2_d3,
                "question_level_1": question_lvl_1, # æ–°å¢ level 1 é—®é¢˜
                "question_level_0": question_lvl_0, # æ–°å¢ level 0 é—®é¢˜
                "original_data_source": input_path.split('/')[-2]
            }
        })

    print(f"\nRæ•°æ®å¤„ç†å®Œæˆï¼š")
    print(f"- æ–°å¢Rè®°å½•æ•°ï¼š{len(reference_records)}")
    print(f"- ç”Ÿæˆæœ‰æ•ˆé—®é¢˜æ•°æ®æ•°ï¼š{len(questions_data)}")
    print(f"- æœ¬æ¬¡åˆ†é…Rç¼–å·èŒƒå›´ï¼š{start_r_id} ~ {current_new_r_id - 1}")
    return questions_data, reference_records

def sample_random_records(records: List[Dict[str, Any]], sample_size: int = 3) -> List[Dict[str, Any]]:
    """ä»è®°å½•ä¸­éšæœºæŠ½å–Næ¡ï¼ˆä¸è¶³åˆ™å…¨éƒ¨è¿”å›ï¼‰ï¼Œç”¨äºé‡å¤æ£€æµ‹"""
    if len(records) <= sample_size:
        return records.copy()
    return random.sample(records, sample_size)

def check_duplicate_qa(qa_path: str, sample_records: List[Dict[str, Any]]) -> bool:
    """
    æ£€æŸ¥æŠ½æ ·çš„QAè®°å½•æ˜¯å¦å·²å­˜åœ¨äºç°æœ‰JSONLæ–‡ä»¶ä¸­
    è¿”å›ï¼šTrue=å­˜åœ¨é‡å¤ï¼ŒFalse=æ— é‡å¤
    """
    if not os.path.exists(qa_path):
        return False  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— é‡å¤
    
    # æå–æŠ½æ ·è®°å½•çš„å…³é”®æ¯”å¯¹å­—æ®µï¼ˆquestion + answerï¼‰
    sample_keys = []
    for record in sample_records:
        key = (
            record.get("question", "").strip(),
            record.get("answer", "").strip(),
        )
        sample_keys.append(key)
    
    # è¯»å–ç°æœ‰QAæ–‡ä»¶ï¼Œæ¯”å¯¹å…³é”®å­—æ®µ
    try:
        with open(qa_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                cleaned_line = line.strip()
                if not cleaned_line:
                    continue
                try:
                    existing = json.loads(cleaned_line)
                    existing_key = (
                        existing.get("question", "").strip(),
                        existing.get("answer", "").strip(),
                    )
                    if existing_key in sample_keys:
                        print(f"âŒ å‘ç°é‡å¤æ•°æ®ï¼ç°æœ‰æ–‡ä»¶ç¬¬{line_num}è¡Œä¸æŠ½æ ·æ•°æ®é‡å¤")
                        print(f"  - é‡å¤questionï¼š{existing.get('question', '')[:50]}...")
                        print(f"  - é‡å¤answerï¼š{existing.get('answer', '')[:30]}...")
                        return True
                except json.JSONDecodeError:
                    continue
    except Exception as e:
        print(f"âš ï¸  è¯»å–ç°æœ‰QAæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}ï¼Œè·³è¿‡é‡å¤æ£€æµ‹")
        return False  # æ£€æµ‹å¤±è´¥æ—¶é»˜è®¤å…è®¸å†™å…¥
    
    return False

def save_output_files(questions_data: List[Dict[str, Any]], new_reference_records: List[Dict[str, Any]],
                     q_output_path: str, r_output_path: str):
    """
    ä¿å­˜è¾“å‡ºæ–‡ä»¶ï¼š
    - é—®é¢˜æ–‡ä»¶ï¼šJSONLæ ¼å¼ï¼ˆè¿½åŠ ä¿å­˜ï¼Œæ¯æ¡ä¸€è¡Œï¼Œlistä¸æ¢è¡Œï¼‰
    - å‚è€ƒæ–‡ä»¶ï¼šJSONLæ ¼å¼ï¼ˆè¿½åŠ ä¿å­˜ï¼Œæ¯æ¡ä¸€è¡Œï¼‰
    """
    # ä¿å­˜QAæ–‡ä»¶ï¼ˆJSONLï¼Œlistä¸æ¢è¡Œï¼‰
    with open(q_output_path, 'a+', encoding='utf-8') as f:
        for record in questions_data:
            # separators=(',', ':') ç¡®ä¿listç´§å‡‘ä¸æ¢è¡Œ
            json.dump(record, f, ensure_ascii=False, separators=(',', ':'))
            f.write('\n')
    print(f"\nQAæ–‡ä»¶å·²è¿½åŠ è‡³ï¼š{q_output_path}")
    # ç»Ÿè®¡QAæ–‡ä»¶æ€»è®°å½•æ•°
    qa_total = sum(1 for line in open(q_output_path, 'r', encoding='utf-8') if line.strip())
    print(f"QAæ–‡ä»¶å½“å‰æ€»è®°å½•æ•°ï¼š{qa_total}")

    # ä¿å­˜å‚è€ƒæ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼Œè¿½åŠ æ¨¡å¼ï¼‰
    with open(r_output_path, 'a+', encoding='utf-8') as f:
        for record in new_reference_records:
            json.dump(record, f, ensure_ascii=False)
            f.write('\n')
    print(f"å‚è€ƒæ–‡ä»¶å·²è¿½åŠ è‡³ï¼š{r_output_path}")
    # ç»Ÿè®¡å‚è€ƒæ–‡ä»¶æ€»è®°å½•æ•°
    ref_total = get_max_existing_r_count(r_output_path)
    print(f"å‚è€ƒæ–‡ä»¶å½“å‰æ€»è®°å½•æ•°ï¼š{ref_total}")

def main():
    parser = argparse.ArgumentParser(description="JSONLæ•°æ®å¤„ç†ï¼šè¿‡æ»¤æ— æ•ˆQA+é‡å¤æ£€æµ‹+å…¨å±€å”¯ä¸€Rç¼–å·")
    parser.add_argument("--input", required=True, help="JSONLæ ¼å¼åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-questions", required=True, help="å…¨å±€QAæ–‡ä»¶è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼Œç´¯ç§¯ä¿å­˜ï¼‰")
    parser.add_argument("--output-references", required=True, help="å…¨å±€å‚è€ƒæ–‡ä»¶è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼Œç´¯ç§¯ä¿å­˜ï¼‰")
    parser.add_argument("--output-invalid", required=True, help="æ— æ•ˆæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼Œå­˜å‚¨answeråœ¨questionä¸­çš„åŸå§‹æ•°æ®ï¼‰")
    args = parser.parse_args()

    global input_path  # å…¨å±€å˜é‡ï¼Œä¾›process_r_reference/filter_invalid_dataä½¿ç”¨
    input_path = args.input

    try:
        # 1. åŠ è½½åŸå§‹æ•°æ®ï¼ˆåŸºç¡€æ ¼å¼/å­—æ®µè¿‡æ»¤ï¼‰
        original_data = load_original_data(args.input)
        if not original_data:
            print("è­¦å‘Šï¼šæœªåŠ è½½åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè„šæœ¬ç»ˆæ­¢")
            return
        
        # 2. è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆanswerå®Œæ•´å‡ºç°åœ¨questionä¸­ï¼‰+ åˆ†ç¦»æ— æ•ˆæ•°æ®
        print("\n==================================================")
        print("ğŸ” å¼€å§‹è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆanswerå®Œæ•´å‡ºç°åœ¨questionä¸­ï¼‰...")
        print("==================================================")
        filtered_data, invalid_data = filter_invalid_data(original_data)
        if not filtered_data:
            print("è­¦å‘Šï¼šè¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®ï¼Œä»…ä¿å­˜æ— æ•ˆæ•°æ®")
            # ä¿å­˜æ— æ•ˆæ•°æ®åç»ˆæ­¢
            save_invalid_data(invalid_data, args.output_invalid)
            return
        
        # 3. ä¿å­˜æ— æ•ˆæ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®ï¼Œéƒ½è¦ä¿å­˜ï¼‰
        save_invalid_data(invalid_data, args.output_invalid)
        
        # 4. è·å–å‚è€ƒæ–‡ä»¶ç°æœ‰Rè®°å½•æ•°ï¼Œç¡®å®šæœ¬æ¬¡èµ·å§‹ç¼–å·
        existing_count = get_max_existing_r_count(args.output_references)
        start_r_id = existing_count + 1
        
        # 5. å¤„ç†Ræ•°æ®å’Œç¼–å·åˆ†é…ï¼ˆä»…å¤„ç†è¿‡æ»¤åçš„æœ‰æ•ˆæ•°æ®ï¼‰
        questions_data, new_reference_records = process_r_reference(filtered_data, start_r_id)
        if not questions_data:
            print("è­¦å‘Šï¼šæœªç”Ÿæˆæœ‰æ•ˆQAæ•°æ®ï¼Œè„šæœ¬ç»ˆæ­¢")
            return
        
        # 6. é‡å¤æ£€æµ‹ï¼šéšæœºæŠ½3æ¡æ¯”å¯¹ç°æœ‰QAæ–‡ä»¶
        print("\n==================================================")
        print("ğŸ” å¼€å§‹é‡å¤æ£€æµ‹...")
        print("==================================================")
        sample_records = sample_random_records(questions_data)
        is_duplicate = check_duplicate_qa(args.output_questions, sample_records)
        if is_duplicate:
            print("âŒ é”™è¯¯ï¼šå½“å‰æ–‡ä»¶æ•°æ®å·²å­˜åœ¨äºQAæ–‡ä»¶ä¸­ï¼Œå·²è·³è¿‡ä¿å­˜ï¼")
            return
        
        # 7. ä¿å­˜è¾“å‡ºæ–‡ä»¶ï¼ˆQA+å‚è€ƒæ–‡ä»¶ï¼‰
        print("\n==================================================")
        print("ğŸ’¾ å¼€å§‹ä¿å­˜æœ‰æ•ˆæ–‡ä»¶...")
        print("==================================================")
        save_output_files(questions_data, new_reference_records, args.output_questions, args.output_references)
        
        print("\nâœ… å¤„ç†å®Œå…¨å®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
        raise  # æŠ›å‡ºå¼‚å¸¸ä¾¿äºè°ƒè¯•

if __name__ == "__main__":
    main()